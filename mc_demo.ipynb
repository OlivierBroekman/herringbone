{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herringbone as hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create an MDP\n",
    "map_names = [\"slides\", \"example\", \"easy\", \"danger_holes\", \"double_fish\", \"wall_of_death\", \"example2\", \"mega\"]\n",
    "selected_map_id = 0\n",
    "\n",
    "state_path = \"herringbone/env_core/config/state_config.json\"\n",
    "map_path = f\"herringbone/env_core/maps/{map_names[selected_map_id]}.csv\"\n",
    "action_path = \"herringbone/env_core/config/action_config.json\"\n",
    "\n",
    "GAMMA = 1\n",
    "\n",
    "demo_mdp = hb.MDP(state_path, map_path, action_path, seed=42, gamma=GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═══════╦═══════╦═══════╦═══════╗\n",
      "║ \u001b[32m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║\n",
      "╠═══════╬═══════╬═══════╬═══════╣\n",
      "║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║\n",
      "╠═══════╬═══════╬═══════╬═══════╣\n",
      "║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║\n",
      "╠═══════╬═══════╬═══════╬═══════╣\n",
      "║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[34m  -1 \u001b[0m ║ \u001b[32m  -1 \u001b[0m ║\n",
      "╚═══════╩═══════╩═══════╩═══════╝[0]\n",
      "t: 0 | S: [2, 3], R: -1, A: ←\n",
      "t: 1 | S: [2, 2], R: -1, A: ↓\n",
      "t: 2 | S: [3, 2], R: -1, A: ↑\n",
      "t: 3 | S: [2, 2], R: -1, A: ↑\n",
      "t: 4 | S: [1, 2], R: -1, A: ↓\n",
      "t: 5 | S: [2, 2], R: -1, A: ↑\n",
      "t: 6 | S: [1, 2], R: -1, A: →\n",
      "t: 7 | S: [1, 3], R: -1, A: ←\n",
      "t: 8 | S: [1, 2], R: -1, A: ↑\n",
      "t: 9 | S: [0, 2], R: -1, A: ↓\n",
      "t: 10 | S: [1, 2], R: -1, A: ←\n",
      "t: 11 | S: [1, 1], R: -1, A: ↓\n",
      "t: 12 | S: [2, 1], R: -1, A: ←\n",
      "t: 13 | S: [2, 0], R: -1, A: →\n",
      "t: 14 | S: [2, 1], R: -1, A: ←\n",
      "t: 15 | S: [2, 0], R: -1, A: ↑\n",
      "t: 16 | S: [1, 0], R: -1, A: ↑\n",
      "t: 17 | S: [0, 0], R: -1, A: None\n",
      "Trajectory(states=[[2, 3], [2, 2], [3, 2], [2, 2], [1, 2], [2, 2], [1, 2], [1, 3], [1, 2], [0, 2], [1, 2], [1, 1], [2, 1], [2, 0], [2, 1], [2, 0], [1, 0], [0, 0]], actions=[←, ↓, ↑, ↑, ↓, ↑, →, ←, ↑, ↓, ←, ↓, ←, →, ←, ↑, ↑], rewards=[nan, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_policy = hb.EpsilonGreedyPolicy(mdp=demo_mdp, epsilon=1)\n",
    "episode = hb.Episode(mdp=demo_mdp, policy=random_policy, max_depth=1000)\n",
    "episode.peek()\n",
    "episode.run(\"sar\")\n",
    "print(episode.trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═════════╦═════════╦═════════╦═════════╗\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╚═════════╩═════════╩═════════╩═════════╝\n"
     ]
    }
   ],
   "source": [
    "policy = hb.EpsilonGreedyPolicy(mdp=demo_mdp, epsilon=1)  # defaults to uniform\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = hb.Episode(mdp=demo_mdp, policy=policy, max_depth=1000)\n",
    "episode.run(\"sar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "mc_predictor = hb.MonteCarloPredictor(demo_mdp)\n",
    "mc_predictor.evaluate_policy(policy, n_samples=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔════════╦════════╦════════╦════════╗\n",
      "║  0.00  ║ -14.34 ║ -20.57 ║ -22.16 ║\n",
      "╠════════╬════════╬════════╬════════╣\n",
      "║ -12.85 ║ -17.76 ║ -20.08 ║ -19.93 ║\n",
      "╠════════╬════════╬════════╬════════╣\n",
      "║ -19.38 ║ -20.06 ║ -17.73 ║ -14.02 ║\n",
      "╠════════╬════════╬════════╬════════╣\n",
      "║ -20.92 ║ -19.65 ║ -12.63 ║  0.00  ║\n",
      "╚════════╩════════╩════════╩════════╝\n"
     ]
    }
   ],
   "source": [
    "hb.Render.preview_V(mdp=demo_mdp, learned_V=mc_predictor.value_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 1000\n",
    "mc_control = hb.MonteCarloController(demo_mdp, epsilon=0.25)\n",
    "mc_control.train(n_episodes=N)\n",
    "trained_policy = mc_control.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[0, 0]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}, [0, 1]: {↑: 0.0625, ↓: 0.0625, ←: 0.8125, →: 0.0625}, [0, 2]: {↑: 0.0625, ↓: 0.0625, ←: 0.8125, →: 0.0625}, [0, 3]: {↑: 0.0625, ↓: 0.0625, ←: 0.8125, →: 0.0625}, [1, 0]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [1, 1]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [1, 2]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [1, 3]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [2, 0]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [2, 1]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [2, 2]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [2, 3]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [3, 0]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [3, 1]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [3, 2]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [3, 3]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}}\n",
      "╔═════════╦═════════╦═════════╦═════════╗\n",
      "║ ↑/↓/←/→ ║    ←    ║    ←    ║    ←    ║\n",
      "╠═════════╬═════════╬═════════╬═════════╣\n",
      "║    ↑    ║    ↑    ║    ↑    ║    ↓    ║\n",
      "╠═════════╬═════════╬═════════╬═════════╣\n",
      "║    →    ║    ↑    ║    ↓    ║    ↓    ║\n",
      "╠═════════╬═════════╬═════════╬═════════╣\n",
      "║    ↑    ║    →    ║    →    ║ ↑/↓/←/→ ║\n",
      "╚═════════╩═════════╩═════════╩═════════╝\n"
     ]
    }
   ],
   "source": [
    "print(trained_policy.get_policy())\n",
    "print(trained_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0 | S: [0, 2], R: -1, A: ←\n",
      "t: 1 | S: [0, 1], R: -1, A: ↓\n",
      "t: 2 | S: [1, 1], R: -1, A: ↑\n",
      "t: 3 | S: [0, 1], R: -1, A: ←\n",
      "t: 4 | S: [0, 0], R: -1, A: None\n"
     ]
    }
   ],
   "source": [
    "episode = hb.Episode(mdp=demo_mdp, policy=trained_policy, max_depth=1000)\n",
    "episode.run(\"sar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
