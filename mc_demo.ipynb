{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herringbone as hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create an MDP\n",
    "map_names = [\"-\", \"example\", \"easy\", \"danger_holes\", \"double_fish\", \"wall_of_death\", \"example2\", \"mega\"]\n",
    "selected_map_id = 3\n",
    "\n",
    "state_path = \"herringbone/env_core/config/state_config.json\"\n",
    "map_path = f\"herringbone/env_core/maps/{map_names[selected_map_id]}.csv\"\n",
    "action_path = \"herringbone/env_core/config/action_config.json\"\n",
    "\n",
    "demo_mdp = hb.MDP(state_path, map_path, action_path, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔════════╦════════╦════════╦════════╦════════╗\n",
      "║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[31m hole \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m<✰))><\u001b[0m ║\n",
      "╠════════╬════════╬════════╬════════╬════════╣\n",
      "║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[31m hole \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║\n",
      "╠════════╬════════╬════════╬════════╬════════╣\n",
      "║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[31m hole \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║\n",
      "╠════════╬════════╬════════╬════════╬════════╣\n",
      "║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[31m hole \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║\n",
      "╠════════╬════════╬════════╬════════╬════════╣\n",
      "║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║ \u001b[34m      \u001b[0m ║\n",
      "╚════════╩════════╩════════╩════════╩════════╝\n",
      "t: 0 | S: [0, 0], R: nan, A: ↑\n",
      "t: 1 | S: [0, 0], R: -1, A: ↓\n",
      "t: 2 | S: [1, 0], R: -1, A: ↑\n",
      "t: 3 | S: [0, 0], R: -1, A: ↑\n",
      "t: 4 | S: [0, 0], R: -1, A: ↑\n",
      "t: 5 | S: [0, 0], R: -1, A: ↓\n",
      "t: 6 | S: [1, 0], R: -1, A: ↑\n",
      "t: 7 | S: [0, 0], R: -1, A: →\n",
      "t: 8 | S: [0, 1], R: -1, A: ←\n",
      "t: 9 | S: [0, 0], R: -1, A: ↑\n",
      "t: 10 | S: [0, 0], R: -1, A: ↓\n",
      "t: 11 | S: [1, 0], R: -1, A: ←\n",
      "t: 12 | S: [1, 0], R: -1, A: ↓\n",
      "t: 13 | S: [2, 0], R: -1, A: ←\n",
      "t: 14 | S: [2, 0], R: -1, A: →\n",
      "t: 15 | S: [2, 1], R: -1, A: ←\n",
      "t: 16 | S: [2, 0], R: -1, A: ↑\n",
      "t: 17 | S: [1, 0], R: -1, A: ↑\n",
      "t: 18 | S: [0, 0], R: -1, A: →\n",
      "t: 19 | S: [0, 1], R: -1, A: ←\n",
      "t: 20 | S: [0, 0], R: -1, A: ←\n",
      "t: 21 | S: [0, 0], R: -1, A: ↑\n",
      "t: 22 | S: [0, 0], R: -1, A: ↓\n",
      "t: 23 | S: [1, 0], R: -1, A: ↑\n",
      "t: 24 | S: [0, 0], R: -1, A: ↑\n",
      "t: 25 | S: [0, 0], R: -1, A: →\n",
      "t: 26 | S: [0, 1], R: -1, A: ←\n",
      "t: 27 | S: [0, 0], R: -1, A: ←\n",
      "t: 28 | S: [0, 0], R: -1, A: ←\n",
      "t: 29 | S: [0, 0], R: -1, A: ↑\n",
      "t: 30 | S: [0, 0], R: -1, A: ↓\n",
      "t: 31 | S: [1, 0], R: -1, A: ↓\n",
      "t: 32 | S: [2, 0], R: -1, A: →\n",
      "t: 33 | S: [2, 1], R: -1, A: ↓\n",
      "t: 34 | S: [3, 1], R: -1, A: ↑\n",
      "t: 35 | S: [2, 1], R: -1, A: ↑\n",
      "t: 36 | S: [1, 1], R: -1, A: →\n",
      "Trajectory(states=[[0, 0], [0, 0], [1, 0], [0, 0], [0, 0], [0, 0], [1, 0], [0, 0], [0, 1], [0, 0], [0, 0], [1, 0], [1, 0], [2, 0], [2, 0], [2, 1], [2, 0], [1, 0], [0, 0], [0, 1], [0, 0], [0, 0], [0, 0], [1, 0], [0, 0], [0, 0], [0, 1], [0, 0], [0, 0], [0, 0], [0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [2, 1], [1, 1]], actions=[↑, ↓, ↑, ↑, ↑, ↓, ↑, →, ←, ↑, ↓, ←, ↓, ←, →, ←, ↑, ↑, →, ←, ←, ↑, ↓, ↑, ↑, →, ←, ←, ←, ↑, ↓, ↓, →, ↓, ↑, ↑, →], rewards=[nan, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_policy = hb.EpsilonGreedyPolicy(mdp=demo_mdp, epsilon=1)\n",
    "episode = hb.Episode(mdp=demo_mdp, policy=random_policy, max_depth=1000)\n",
    "episode.peek()\n",
    "episode.run(\"sar\")\n",
    "print(episode.trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the render function for previewing a Value Function (hate this!)\n",
    "def preview_V(mdp, learned_V):\n",
    "    \n",
    "    states_2d = mdp.get_board().states\n",
    "    x = len(states_2d)\n",
    "    y = len(states_2d[0])\n",
    "    \n",
    "    v_values =  ['%.2f' % v for v in list(learned_V.values())]\n",
    "\n",
    "    two_d_list = [v_values[i * y:(i + 1) * y] for i in range(x)]\n",
    "\n",
    "    # Print 2D list\n",
    "    for row in two_d_list:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═════════╦═════════╦═════════╦═════════╦═════════╗\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║ ↑/↓/←/→ ║\n",
      "╚═════════╩═════════╩═════════╩═════════╩═════════╝\n"
     ]
    }
   ],
   "source": [
    "policy = hb.EpsilonGreedyPolicy(mdp=demo_mdp, epsilon=1)  # defaults to uniform\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = hb.Episode(mdp=demo_mdp, policy=policy, max_depth=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0 | S: [0, 0], R: nan, A: ↓\n",
      "t: 1 | S: [1, 0], R: -1, A: ←\n",
      "t: 2 | S: [1, 0], R: -1, A: →\n",
      "t: 3 | S: [1, 1], R: -1, A: →\n"
     ]
    }
   ],
   "source": [
    "episode.run(\"sar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOUNT = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "mc_predictor = hb.MonteCarloPredictor(demo_mdp, discount=DISCOUNT)\n",
    "mc_predictor.evaluate_policy(policy, n_samples=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-5.62', '-4.97', '0.00', '-3.76', '0.00']\n",
      "['-5.84', '-5.11', '0.00', '-2.97', '-3.20']\n",
      "['-5.99', '-5.18', '0.00', '-3.23', '-3.18']\n",
      "['-6.18', '-5.51', '0.00', '-5.83', '-6.25']\n",
      "['-6.58', '-5.63', '-6.19', '-6.21', '-7.03']\n"
     ]
    }
   ],
   "source": [
    "preview_V(demo_mdp, mc_predictor.value_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 1000\n",
    "mc_control = hb.MonteCarloController(demo_mdp, discount=DISCOUNT, epsilon=0.25, start_coords=(0,0))\n",
    "mc_control.train(n_episodes=N)\n",
    "trained_policy = mc_control.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{[0, 0]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [0, 1]: {↑: 0.0625, ↓: 0.0625, ←: 0.8125, →: 0.0625}, [0, 2]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}, [0, 3]: {↑: 0.0854196364216137, ↓: 0.07342895886356467, ←: 0.060680322166050904, →: 0.7804710825487706}, [0, 4]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}, [1, 0]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [1, 1]: {↑: 0.0625, ↓: 0.0625, ←: 0.8125, →: 0.0625}, [1, 2]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}, [1, 3]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [1, 4]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [2, 0]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [2, 1]: {↑: 0.0625, ↓: 0.0625, ←: 0.8125, →: 0.0625}, [2, 2]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}, [2, 3]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [2, 4]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [3, 0]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [3, 1]: {↑: 0.0625, ↓: 0.8125, ←: 0.0625, →: 0.0625}, [3, 2]: {↑: 0.25, ↓: 0.25, ←: 0.25, →: 0.25}, [3, 3]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [3, 4]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}, [4, 0]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [4, 1]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [4, 2]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [4, 3]: {↑: 0.0625, ↓: 0.0625, ←: 0.0625, →: 0.8125}, [4, 4]: {↑: 0.8125, ↓: 0.0625, ←: 0.0625, →: 0.0625}}\n",
      "╔═════════╦═════════╦═════════╦═════════╦═════════╗\n",
      "║    ↓    ║    ←    ║ ↑/↓/←/→ ║    →    ║ ↑/↓/←/→ ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║    ↓    ║    ←    ║ ↑/↓/←/→ ║    →    ║    ↑    ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║    ↓    ║    ←    ║ ↑/↓/←/→ ║    →    ║    ↑    ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║    ↓    ║    ↓    ║ ↑/↓/←/→ ║    →    ║    ↑    ║\n",
      "╠═════════╬═════════╬═════════╬═════════╬═════════╣\n",
      "║    →    ║    →    ║    →    ║    →    ║    ↑    ║\n",
      "╚═════════╩═════════╩═════════╩═════════╩═════════╝\n"
     ]
    }
   ],
   "source": [
    "print(trained_policy.get_policy())\n",
    "print(trained_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0 | S: [0, 0], R: nan, A: →\n",
      "t: 1 | S: [0, 1], R: -1, A: →\n",
      "t: 2 | S: [0, 2], R: -1, A: →\n",
      "t: 3 | S: [0, 3], R: -1, A: ↓\n",
      "t: 4 | S: [1, 3], R: -1, A: →\n",
      "t: 5 | S: [1, 4], R: -1, A: ↓\n"
     ]
    }
   ],
   "source": [
    "episode = hb.Episode(mdp=demo_mdp, policy=trained_policy, max_depth=1000)\n",
    "episode.run(\"sar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "mc_predictor = hb.MonteCarloPredictor(demo_mdp, discount=DISCOUNT)\n",
    "mc_predictor.evaluate_policy(trained_policy, n_samples=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-4.95', '-4.31', '-3.53', '-2.64', '-1.60']\n",
      "['-4.46', '-3.69', '-2.65', '-1.63', '-2.11']\n",
      "['-3.63', '-2.75', '-1.72', '-2.15', '0.00']\n"
     ]
    }
   ],
   "source": [
    "preview_V(demo_mdp, mc_predictor.value_functions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
